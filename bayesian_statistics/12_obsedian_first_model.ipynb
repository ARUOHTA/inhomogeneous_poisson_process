{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from   numpy.linalg import inv\n",
    "import numpy.random as npr\n",
    "from   pypolyagamma import PyPolyaGamma\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely import wkt\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "from bayesian_statistics.utils_2 import *\n",
    "import japanize_matplotlib\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ohta/dev/bayesian_statistics/data/\"\n",
    "\n",
    "df_elevation = pl.read_csv(os.path.join(data_dir, \"gdf_elevation_with_costs.csv\"))\n",
    "df_result = pl.read_csv(os.path.join(data_dir, \"11_gdf_obsedian.csv\"))\n",
    "df_sites = pl.read_csv(os.path.join(data_dir, \"11_gdf_sites.csv\"))\n",
    "\n",
    "time_period_name = {\n",
    "    0: \"早期・早々期\",\n",
    "    1: \"前期\",\n",
    "    2: \"中期\",\n",
    "    3: \"後期\",\n",
    "    4: \"晩期\"\n",
    "}\n",
    "\n",
    "origin_order = [\"神津島\", \"信州\", \"箱根\", \"高原山\", \"その他\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "地点ごとの産地構成比を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_grid(\n",
    "    df: pl.DataFrame,\n",
    "    grid_size: int = 100\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    解析領域全体をカバーする等間隔グリッドを作成\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム（緯度・経度を含む）\n",
    "    grid_size : int\n",
    "        グリッドの分割数\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        緯度・経度のメッシュグリッド (lat_mesh, lon_mesh)\n",
    "    \"\"\"\n",
    "    lon_min, lon_max = df['経度'].min(), df['経度'].max()\n",
    "    lat_min, lat_max = df['緯度'].min(), df['緯度'].max()\n",
    "    \n",
    "    lon_grid = np.linspace(lon_min, lon_max, grid_size)\n",
    "    lat_grid = np.linspace(lat_min, lat_max, grid_size)\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)\n",
    "    \n",
    "    return lon_mesh, lat_mesh\n",
    "\n",
    "def create_elevation_grid(df_elevation: pl.DataFrame) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    df_elevationのすべての地点を含むグリッドを作成\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_elevation : pl.DataFrame\n",
    "        地形データフレーム（x: 経度, y: 緯度を含む）\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        緯度・経度のメッシュグリッド (lat_mesh, lon_mesh)\n",
    "    \"\"\"\n",
    "    # ユニークな経度・緯度の値を取得（ソートされた形で）\n",
    "    unique_lons = df_elevation['x'].unique().sort()\n",
    "    unique_lats = df_elevation['y'].unique().sort()\n",
    "    \n",
    "    # メッシュグリッドを作成\n",
    "    lon_mesh, lat_mesh = np.meshgrid(\n",
    "        unique_lons.to_numpy(),  # 経度の一意な値\n",
    "        unique_lats.to_numpy()   # 緯度の一意な値\n",
    "    )\n",
    "    \n",
    "    return lon_mesh, lat_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    df: pl.DataFrame,\n",
    "    target_period: int,\n",
    "    target_origin: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    解析用のデータを前処理\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "    target_period : int\n",
    "        対象時期\n",
    "    target_origin : str\n",
    "        対象産地カテゴリ\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    site_coords : np.ndarray\n",
    "        遺跡の座標（ラジアン）\n",
    "    counts : np.ndarray\n",
    "        各遺跡での出土数\n",
    "    target_counts : np.ndarray\n",
    "        対象産地の出土数\n",
    "    \"\"\"\n",
    "    # 対象時期のデータのみ抽出\n",
    "    period_df = df.filter(pl.col('時期') == target_period)\n",
    "\n",
    "    site_ids = period_df['遺跡ID'].to_numpy()\n",
    "    \n",
    "    # 合計出土数\n",
    "    counts = np.ones(len(period_df))\n",
    "    \n",
    "    # 対象産地の出土数\n",
    "    target_counts = period_df.with_columns(\n",
    "        pl.when(pl.col('産地カテゴリ') == target_origin)\n",
    "        .then(1)\n",
    "        .otherwise(0)\n",
    "        .alias('target_count')\n",
    "    )['target_count'].to_numpy()\n",
    "    \n",
    "    return site_ids, counts, target_counts\n",
    "\n",
    "def create_site_coords(df: pl.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    遺跡の座標をラジアンに変換\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        遺跡の座標（ラジアン）\n",
    "    \"\"\"\n",
    "    # 座標をラジアンに変換\n",
    "    coords = (\n",
    "        df_result\n",
    "        .select([\n",
    "            (pl.col(\"遺跡ID\")), \n",
    "            (pl.col('緯度') * np.pi / 180).alias('lat_rad'),\n",
    "            (pl.col('経度') * np.pi / 180).alias('lon_rad')\n",
    "        ])\n",
    "        .unique(subset=[\"遺跡ID\"])\n",
    "        .sort(\"遺跡ID\")\n",
    "    )\n",
    "    \n",
    "    # 座標と出土数を numpy 配列に変換\n",
    "    site_coords = np.column_stack([\n",
    "        coords['lat_rad'].to_numpy(),\n",
    "        coords['lon_rad'].to_numpy()\n",
    "    ])\n",
    "\n",
    "    return site_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights_matrix(\n",
    "    grid_coords: np.ndarray,\n",
    "    site_coords: np.ndarray,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    重み行列を計算\n",
    "    \"\"\"\n",
    "    R = 6371  # 地球の半径(km)\n",
    "    \n",
    "    # 通常の距離計算\n",
    "    dlat = grid_coords[:, np.newaxis, 0] - site_coords[np.newaxis, :, 0]\n",
    "    dlon = grid_coords[:, np.newaxis, 1] - site_coords[np.newaxis, :, 1]\n",
    "    \n",
    "    a = (np.sin(dlat/2)**2 + \n",
    "         np.cos(grid_coords[:, np.newaxis, 0]) * \n",
    "         np.cos(site_coords[np.newaxis, :, 0]) * \n",
    "         np.sin(dlon/2)**2)\n",
    "    \n",
    "    distances = 2 * R * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    # 重みの初期計算\n",
    "    weights = np.exp(-0.5 * (distances**2) / (sigma**2)) / (2 * np.pi * sigma**2)\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_matrix(weights, grid_coords, df_elevation, lon_mesh, lat_mesh):\n",
    "    # 地形マスクの作成\n",
    "    land_points = df_elevation.select([\n",
    "        'x',\n",
    "        'y',\n",
    "        pl.col('is_sea').cast(pl.Boolean)\n",
    "    ]).to_numpy()\n",
    "    \n",
    "    lons_1d = lon_mesh[0, :]\n",
    "    lats_1d = lat_mesh[:, 0]\n",
    "    land_mask = np.full(lon_mesh.shape, False)\n",
    "    \n",
    "    x_indices = np.searchsorted(lons_1d, land_points[:, 0])\n",
    "    y_indices = np.searchsorted(lats_1d, land_points[:, 1])\n",
    "    valid_points = (\n",
    "        (x_indices > 0) & \n",
    "        (x_indices < len(lons_1d)) & \n",
    "        (y_indices > 0) & \n",
    "        (y_indices < len(lats_1d))\n",
    "    )\n",
    "    is_sea = land_points[valid_points, 2].astype(bool)\n",
    "    land_mask[y_indices[valid_points], x_indices[valid_points]] = ~is_sea\n",
    "    \n",
    "    # grid_coordsの各点について、対応するland_maskの値を取得\n",
    "    grid_lons = grid_coords[:, 1] * 180/np.pi  # ラジアンから度に変換\n",
    "    grid_lats = grid_coords[:, 0] * 180/np.pi\n",
    "    \n",
    "    grid_x_indices = np.searchsorted(lons_1d, grid_lons)\n",
    "    grid_y_indices = np.searchsorted(lats_1d, grid_lats)\n",
    "    \n",
    "    # インデックスが有効範囲内にあることを確認\n",
    "    valid_grid_points = (\n",
    "        (grid_x_indices > 0) & \n",
    "        (grid_x_indices < len(lons_1d)) & \n",
    "        (grid_y_indices > 0) & \n",
    "        (grid_y_indices < len(lats_1d))\n",
    "    )\n",
    "    \n",
    "    # 海上の点の重みを0に設定\n",
    "    grid_is_land = np.zeros(len(grid_coords), dtype=bool)\n",
    "    grid_is_land[valid_grid_points] = land_mask[\n",
    "        grid_y_indices[valid_grid_points],\n",
    "        grid_x_indices[valid_grid_points]\n",
    "    ]\n",
    "    \n",
    "    # 海上の点からの重みをすべて0に\n",
    "    weights = weights * grid_is_land[:, np.newaxis]\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_ratios(\n",
    "    weights: np.ndarray,\n",
    "    counts: np.ndarray,\n",
    "    target_counts: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    重み付き比率を計算\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : np.ndarray\n",
    "        重み行列\n",
    "    counts : np.ndarray\n",
    "        各遺跡での出土数\n",
    "    target_counts : np.ndarray\n",
    "        対象産地の出土数\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ratios : np.ndarray\n",
    "        各グリッド点での重み付き比率\n",
    "    \"\"\"\n",
    "    # 重み付き合計を計算\n",
    "    weighted_total = np.sum(weights * counts, axis=1)\n",
    "    weighted_target = np.sum(weights * target_counts, axis=1)\n",
    "    \n",
    "    # 比率計算（0除算を防ぐ）\n",
    "    ratios = np.where(\n",
    "        weighted_total > 0,\n",
    "        weighted_target / weighted_total,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_grid_ratios(\n",
    "    lon_mesh: np.ndarray,\n",
    "    lat_mesh: np.ndarray,\n",
    "    ratio_mesh: np.ndarray,\n",
    "    df: pl.DataFrame,\n",
    "    target_period: int,\n",
    "    target_origin: str,\n",
    "    radius_km: float,\n",
    "    figsize: tuple = (12, 8)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    グリッド点での比率を可視化（0-1の範囲に固定）\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # グリッド点での比率をプロット（0-1の範囲に固定）\n",
    "    contour = ax.contourf(\n",
    "        lon_mesh, lat_mesh, ratio_mesh,\n",
    "        levels=np.linspace(0, 1, 21),  # 0から1までを20等分\n",
    "        cmap='Blues',\n",
    "        alpha=0.7,\n",
    "        vmin=0,  # 最小値を0に固定\n",
    "        vmax=1   # 最大値を1に固定\n",
    "    )\n",
    "    \n",
    "    # 元のデータ点も表示\n",
    "    unique_sites = df.unique(subset=['遺跡ID'])\n",
    "    ax.scatter(\n",
    "        unique_sites['経度'],\n",
    "        unique_sites['緯度'],\n",
    "        c='black',\n",
    "        alpha=0.2,\n",
    "        s=10\n",
    "    )\n",
    "    \n",
    "    # タイトルと軸ラベル\n",
    "    time_period_name = {\n",
    "        0: \"早期・早々期\", 1: \"前期\", 2: \"中期\", \n",
    "        3: \"後期\", 4: \"晩期\"\n",
    "    }\n",
    "    ax.set_title(f'Obsidian Ratio Distribution (Grid-based)\\n'\n",
    "              f'Period: {time_period_name[target_period]}, '\n",
    "              f'Origin: {target_origin}, Radius: {radius_km}km')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    # カラーバー（0-1の範囲に固定）\n",
    "    plt.colorbar(contour, ax=ax, label='Ratio', ticks=np.linspace(0, 1, 6))\n",
    "    \n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_obsedian_weight(\n",
    "    df: pl.DataFrame,\n",
    "    df_elevation: pl.DataFrame,\n",
    "    sigma: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    黒曜石の分布をプロットする関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "    df_elevation : pl.DataFrame\n",
    "        標高データフレーム\n",
    "    sigma : int\n",
    "        ガウス分布の標準偏差\n",
    "    target_period : int\n",
    "        対象時期\n",
    "    target_origin : str\n",
    "        対象産地カテゴリ\n",
    "    grid_size : int\n",
    "        グリッドのサイズ\n",
    "    figsize : tuple\n",
    "        プロットのサイズ\n",
    "    \"\"\"\n",
    "    # グリッドの作成\n",
    "    # lon_mesh, lat_mesh = create_base_grid(df, grid_size)\n",
    "\n",
    "    lon_mesh, lat_mesh = create_elevation_grid(df_elevation)\n",
    "\n",
    "    print(lon_mesh.shape, lat_mesh.shape)\n",
    "\n",
    "    # データの前処理\n",
    "    site_coords = create_site_coords(df)\n",
    "\n",
    "    # グリッド座標の準備\n",
    "    grid_coords = np.column_stack([\n",
    "        lat_mesh.ravel() * np.pi / 180,\n",
    "        lon_mesh.ravel() * np.pi / 180\n",
    "    ])\n",
    "\n",
    "    print(\"creating weights matrix...\")\n",
    "    print(f\"grid_coords: {grid_coords.shape}, site_coords: {site_coords.shape}\")\n",
    "    # 陸地のみの重み行列の計算\n",
    "    weights = calculate_weights_matrix(\n",
    "        grid_coords, site_coords, sigma\n",
    "    )\n",
    "\n",
    "    print(f\"weights: {weights.shape}\")\n",
    "\n",
    "    print(\"updating weights matrix...\")\n",
    "    # 重みの更新\n",
    "    weights_updated = update_weights_matrix(weights, grid_coords, df_elevation, lon_mesh, lat_mesh)\n",
    "\n",
    "    return lon_mesh, lat_mesh, weights_updated\n",
    "\n",
    "def calculate_obsedian_ratio(\n",
    "        df: pl.DataFrame,\n",
    "        target_period: int,\n",
    "        target_origin: str,\n",
    "        weights: np.ndarray,\n",
    "        lon_mesh: np.ndarray,\n",
    "        lat_mesh: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    # ここからtarget_period, target_originに依存する処理\n",
    "    site_ids, counts, target_counts = preprocess_data(\n",
    "        df, target_period, target_origin\n",
    "    )\n",
    "    # まず、weightsの2次元目は遺跡IDに対応するので、weights[:, i]がi番目の遺跡に対応する重み。これを、site_idsに対応するように変換する\n",
    "    weights_updated = np.take(weights, site_ids, axis=1)\n",
    "\n",
    "    # 重み付き比率の計算\n",
    "    ratios = calculate_ratios(weights_updated, counts, target_counts)\n",
    "\n",
    "    ratio_mesh = ratios.reshape(lon_mesh.shape)\n",
    "\n",
    "    return lon_mesh, lat_mesh, ratio_mesh\n",
    "    \n",
    "\n",
    "def plot_obsidian_distribution(\n",
    "    df: pl.DataFrame,\n",
    "    df_elevation: pl.DataFrame,\n",
    "    lon_mesh: np.ndarray,\n",
    "    lat_mesh: np.ndarray,\n",
    "    ratio_mesh: np.ndarray,\n",
    "    plot_df: pl.DataFrame,\n",
    "    sigma: int,\n",
    "    target_period: int,\n",
    "    target_origin: str,\n",
    "    grid_size: int,\n",
    "    figsize: tuple = (8, 6)\n",
    ") -> None:\n",
    "    \n",
    "\n",
    "    print(\"plotting...\")\n",
    "    # プロット\n",
    "    plot_grid_ratios(\n",
    "        lon_mesh, lat_mesh, ratio_mesh,\n",
    "        df, target_period, target_origin,\n",
    "        sigma, figsize\n",
    "    )\n",
    "    \n",
    "    plt.scatter(\n",
    "        plot_df[\"経度\"], \n",
    "        plot_df[\"緯度\"], \n",
    "        c=plot_df[\"比率\"], \n",
    "        cmap=\"Blues\", \n",
    "        edgecolors=\"white\", \n",
    "        linewidths=0.5,\n",
    "        vmin=0,\n",
    "        vmax=1 \n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_site_ratios_fast(\n",
    "    df: pl.DataFrame,\n",
    "    sigma: float,\n",
    "    target_period: int,\n",
    "    target_origin: str\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    各遺跡地点での比率を高速計算\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "    radius_km : float\n",
    "        計算する円の半径(km)\n",
    "    target_period : int\n",
    "        対象時期(0-4)\n",
    "    target_origin : str\n",
    "        対象産地カテゴリ\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        緯度、経度、比率を含むDataFrame\n",
    "    \"\"\"\n",
    "    # 遺跡の一意な地点を取得\n",
    "    unique_sites = df.unique(subset=['遺跡ID']).sort('遺跡ID')\n",
    "    \n",
    "    # データの前処理（全遺跡の出土データ）\n",
    "    site_coords = create_site_coords(df)\n",
    "    \n",
    "    # 計算対象の遺跡の座標をラジアンに変換\n",
    "    target_coords = np.column_stack([\n",
    "        unique_sites['緯度'].to_numpy() * np.pi / 180,\n",
    "        unique_sites['経度'].to_numpy() * np.pi / 180\n",
    "    ])\n",
    "    \n",
    "    # 距離行列の計算\n",
    "    # 陸地のみの重み行列の計算\n",
    "    weights = calculate_weights_matrix(\n",
    "            target_coords, site_coords, sigma\n",
    "    )\n",
    "\n",
    "    # 重みの更新\n",
    "    weights_updated = update_weights_matrix(weights, target_coords, df_elevation, lon_mesh, lat_mesh)\n",
    "\n",
    "    # ここからtarget_period, target_originに依存する処理\n",
    "    site_ids, counts, target_counts = preprocess_data(\n",
    "        df, target_period, target_origin\n",
    "    )\n",
    "\n",
    "    weights_updated = np.take(weights_updated, site_ids, axis=1)\n",
    "    \n",
    "    # 比率の計算\n",
    "    ratios = calculate_ratios(weights_updated, counts, target_counts)\n",
    "\n",
    "    # いったんすべての結果をDataFrameに変換\n",
    "    temp_df = pl.DataFrame({\n",
    "        '遺跡ID': unique_sites['遺跡ID'],\n",
    "        f\"比率_{target_period}_{target_origin}\": ratios\n",
    "    })\n",
    "    \n",
    "    # 比率が0より大きい地点のみをフィルタリング\n",
    "    result_df = temp_df.filter(pl.col(f\"比率_{target_period}_{target_origin}\") > 0)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_obsedian_weight\n",
    "lon_mesh, lat_mesh, weights = calculate_obsedian_weight(df_result, df_elevation, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(time_period_name.keys()), origin_order[:-1]のすべての組み合わせを作成\n",
    "\n",
    "ratio_df = pl.DataFrame({\n",
    "    'x': lon_mesh.ravel(),\n",
    "    'y': lat_mesh.ravel()\n",
    "})\n",
    "\n",
    "ratio_sites_df = pl.DataFrame({\n",
    "    '遺跡ID': df_sites['遺跡ID']\n",
    "})\n",
    "    \n",
    "\n",
    "for target_period in time_period_name.keys():\n",
    "    for target_origin in origin_order[:-1]:\n",
    "\n",
    "        print(f\"target_period: {target_period}, target_origin: {target_origin}\")\n",
    "\n",
    "        lon_mesh, lat_mesh, ratio_mesh = calculate_obsedian_ratio(\n",
    "            df = df_result, \n",
    "            target_period = target_period,\n",
    "            target_origin = target_origin,\n",
    "            weights = weights,\n",
    "            lon_mesh = lon_mesh,\n",
    "            lat_mesh = lat_mesh\n",
    "        )\n",
    "\n",
    "        ratio_df = ratio_df.join(\n",
    "            pl.DataFrame({\n",
    "                'x': lon_mesh.ravel(),\n",
    "                'y': lat_mesh.ravel(),\n",
    "                f\"ratio_{target_period}_{target_origin}\": ratio_mesh.ravel()\n",
    "            }),\n",
    "            on=[\"x\", \"y\"]\n",
    "        )\n",
    "\n",
    "        ratio_sites_df = ratio_sites_df.join(\n",
    "            calculate_site_ratios_fast(\n",
    "                df = df_result,\n",
    "                sigma = sigma,\n",
    "                target_period = target_period,\n",
    "                target_origin = target_origin\n",
    "            ),\n",
    "            on=\"遺跡ID\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elevation = df_elevation.join(\n",
    "    ratio_df,\n",
    "    on=[\"x\", \"y\"]\n",
    ")\n",
    "df_sites = df_sites.join(\n",
    "    ratio_sites_df,\n",
    "    on=\"遺跡ID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elevation.write_csv(os.path.join(data_dir, \"12_gdf_elevation_with_ratio.csv\"))\n",
    "df_sites.write_csv(os.path.join(data_dir, \"12_gdf_sites_with_ratio.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
