{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地点ごとの産地構成比を計算\n",
    "\n",
    "def preprocess_data(\n",
    "    df: pl.DataFrame,\n",
    "    target_period: int,\n",
    "    target_origin: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    解析用のデータを前処理\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "    target_period : int\n",
    "        対象時期\n",
    "    target_origin : str\n",
    "        対象産地カテゴリ\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    counts : np.ndarray\n",
    "        各遺跡での出土数（インデックスが遺跡ID）\n",
    "    target_counts : np.ndarray\n",
    "        対象産地の出土数（インデックスが遺跡ID）\n",
    "    \"\"\"\n",
    "    # 全遺跡IDのリストを取得\n",
    "    max_site_id = df['遺跡ID'].max()\n",
    "    \n",
    "    # 対象時期のデータのみ抽出\n",
    "    period_df = df.filter(pl.col('時期') == target_period)\n",
    "    \n",
    "    # 全体のカウント\n",
    "    counts = (\n",
    "        period_df\n",
    "        .group_by('遺跡ID')\n",
    "        .agg([pl.len().alias('count')])\n",
    "        .join(\n",
    "            pl.DataFrame({\n",
    "                '遺跡ID': np.arange(max_site_id + 1)\n",
    "            }),\n",
    "            on='遺跡ID',\n",
    "            how='right'\n",
    "        )\n",
    "        .fill_null(0)\n",
    "        .sort('遺跡ID')['count']\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    # 対象産地のカウント\n",
    "    target_counts = (\n",
    "        period_df\n",
    "        .filter(pl.col('産地カテゴリ') == target_origin)\n",
    "        .group_by('遺跡ID')\n",
    "        .agg([pl.len().alias('count')])\n",
    "        .join(\n",
    "            pl.DataFrame({\n",
    "                '遺跡ID': np.arange(max_site_id + 1)\n",
    "            }),\n",
    "            on='遺跡ID',\n",
    "            how='right'\n",
    "        )\n",
    "        .fill_null(0)\n",
    "        .sort('遺跡ID')['count']\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    return counts, target_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_site_coords(df: pl.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    遺跡の座標をラジアンに変換\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        遺跡の座標（ラジアン）\n",
    "    \"\"\"\n",
    "    # 座標をラジアンに変換\n",
    "    coords = (\n",
    "        df\n",
    "        .select([\n",
    "            (pl.col(\"遺跡ID\")), \n",
    "            (pl.col('緯度') * np.pi / 180).alias('lat_rad'),\n",
    "            (pl.col('経度') * np.pi / 180).alias('lon_rad')\n",
    "        ])\n",
    "        .unique(subset=[\"遺跡ID\"])\n",
    "        .sort(\"遺跡ID\")\n",
    "    )\n",
    "    \n",
    "    # 座標と出土数を numpy 配列に変換\n",
    "    site_coords = np.column_stack([\n",
    "        coords['lat_rad'].to_numpy(),\n",
    "        coords['lon_rad'].to_numpy()\n",
    "    ])\n",
    "\n",
    "    return site_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights_matrix(\n",
    "    grid_coords: np.ndarray, #(N, 2)\n",
    "    site_coords: np.ndarray, #(M, 2)\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    重み行列を計算\n",
    "    \"\"\"\n",
    "    R = 6371  # 地球の半径(km)\n",
    "    \n",
    "    # 通常の距離計算\n",
    "    dlat = grid_coords[:, np.newaxis, 0] - site_coords[np.newaxis, :, 0]\n",
    "    dlon = grid_coords[:, np.newaxis, 1] - site_coords[np.newaxis, :, 1]\n",
    "    \n",
    "    a = (np.sin(dlat/2)**2 + \n",
    "         np.cos(grid_coords[:, np.newaxis, 0]) * \n",
    "         np.cos(site_coords[np.newaxis, :, 0]) * \n",
    "         np.sin(dlon/2)**2)\n",
    "    \n",
    "    distances = 2 * R * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    # 重みの初期計算\n",
    "    def K(x, sigma):\n",
    "        return np.exp(-0.5 * (x**2) / (sigma**2)) / (2 * np.pi * sigma**2)\n",
    "    \n",
    "    weights = K(distances, sigma)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_land_mask(grid_coords, df_elevation, lon_mesh, lat_mesh):\n",
    "    # 地形マスクの作成\n",
    "    land_points = df_elevation.select([\n",
    "        'x',\n",
    "        'y',\n",
    "        pl.col('is_sea').cast(pl.Boolean)\n",
    "    ]).to_numpy()\n",
    "    \n",
    "    lons_1d = lon_mesh[0, :]\n",
    "    lats_1d = lat_mesh[:, 0]\n",
    "    land_mask = np.full(lon_mesh.shape, False)\n",
    "    \n",
    "    x_indices = np.searchsorted(lons_1d, land_points[:, 0])\n",
    "    y_indices = np.searchsorted(lats_1d, land_points[:, 1])\n",
    "    valid_points = (\n",
    "        (x_indices > 0) & \n",
    "        (x_indices < len(lons_1d)) & \n",
    "        (y_indices > 0) & \n",
    "        (y_indices < len(lats_1d))\n",
    "    )\n",
    "    is_sea = land_points[valid_points, 2].astype(bool)\n",
    "    land_mask[y_indices[valid_points], x_indices[valid_points]] = ~is_sea\n",
    "    \n",
    "    # grid_coordsの各点について、対応するland_maskの値を取得\n",
    "    grid_lons = grid_coords[:, 1] * 180/np.pi  # ラジアンから度に変換\n",
    "    grid_lats = grid_coords[:, 0] * 180/np.pi\n",
    "    \n",
    "    grid_x_indices = np.searchsorted(lons_1d, grid_lons)\n",
    "    grid_y_indices = np.searchsorted(lats_1d, grid_lats)\n",
    "    \n",
    "    # インデックスが有効範囲内にあることを確認\n",
    "    valid_grid_points = (\n",
    "        (grid_x_indices > 0) & \n",
    "        (grid_x_indices < len(lons_1d)) & \n",
    "        (grid_y_indices > 0) & \n",
    "        (grid_y_indices < len(lats_1d))\n",
    "    )\n",
    "    \n",
    "    # 海上の点の重みを0に設定\n",
    "    grid_is_land = np.zeros(len(grid_coords), dtype=bool)\n",
    "    grid_is_land[valid_grid_points] = land_mask[\n",
    "        grid_y_indices[valid_grid_points],\n",
    "        grid_x_indices[valid_grid_points]\n",
    "    ]\n",
    "\n",
    "    return grid_is_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ratios(\n",
    "    weights: np.ndarray,\n",
    "    counts: np.ndarray,\n",
    "    target_counts: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    重み付き比率を計算\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : np.ndarray\n",
    "        重み行列\n",
    "    counts : np.ndarray\n",
    "        各遺跡での出土数\n",
    "    target_counts : np.ndarray\n",
    "        対象産地の出土数\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ratios : np.ndarray\n",
    "        各グリッド点での重み付き比率\n",
    "    \"\"\"\n",
    "    # 重み付き合計を計算\n",
    "    weighted_total = np.sum(weights * counts, axis=1)\n",
    "    weighted_target = np.sum(weights * target_counts, axis=1)\n",
    "    \n",
    "    # 比率計算（0除算を防ぐ）\n",
    "    ratios = np.where(\n",
    "        weighted_total > 0,\n",
    "        weighted_target / weighted_total,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ohta/dev/bayesian_statistics/data/\"\n",
    "\n",
    "df_elevation = pl.read_csv(os.path.join(data_dir, \"11_gdf_elevation.csv\"))\n",
    "df_obsidian = pl.read_csv(os.path.join(data_dir, \"11_gdf_obsidian.csv\"))\n",
    "df_sites = pl.read_csv(os.path.join(data_dir, \"11_gdf_sites.csv\"))\n",
    "\n",
    "time_period_name = {\n",
    "    0: \"早期・早々期\",\n",
    "    1: \"前期\",\n",
    "    2: \"中期\",\n",
    "    3: \"後期\",\n",
    "    4: \"晩期\"\n",
    "}\n",
    "\n",
    "origin_order = [\"神津島\", \"信州\", \"箱根\", \"高原山\", \"その他\"]\n",
    "\n",
    "sigma = 14\n",
    "sigma_for_sites = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1420, 956) (1420, 956)\n",
      "creating weights matrix...\n",
      "updating weights matrix...\n",
      "target_period: 0, target_origin: 神津島\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_435283/2700593529.py:30: RuntimeWarning: invalid value encountered in divide\n",
      "  weighted_target / weighted_total,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_period: 0, target_origin: 信州\n",
      "target_period: 0, target_origin: 箱根\n",
      "target_period: 0, target_origin: 高原山\n",
      "target_period: 1, target_origin: 神津島\n",
      "target_period: 1, target_origin: 信州\n",
      "target_period: 1, target_origin: 箱根\n",
      "target_period: 1, target_origin: 高原山\n",
      "target_period: 2, target_origin: 神津島\n",
      "target_period: 2, target_origin: 信州\n",
      "target_period: 2, target_origin: 箱根\n",
      "target_period: 2, target_origin: 高原山\n",
      "target_period: 3, target_origin: 神津島\n",
      "target_period: 3, target_origin: 信州\n",
      "target_period: 3, target_origin: 箱根\n",
      "target_period: 3, target_origin: 高原山\n",
      "target_period: 4, target_origin: 神津島\n",
      "target_period: 4, target_origin: 信州\n",
      "target_period: 4, target_origin: 箱根\n",
      "target_period: 4, target_origin: 高原山\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/ohta/dev/bayesian_statistics/data/\"\n",
    "\n",
    "df_elevation = pl.read_csv(os.path.join(data_dir, \"11_gdf_elevation.csv\"))\n",
    "df_obsidian = pl.read_csv(os.path.join(data_dir, \"11_gdf_obsidian.csv\"))\n",
    "df_sites = pl.read_csv(os.path.join(data_dir, \"11_gdf_sites.csv\"))\n",
    "\n",
    "time_period_name = {\n",
    "    0: \"早期・早々期\",\n",
    "    1: \"前期\",\n",
    "    2: \"中期\",\n",
    "    3: \"後期\",\n",
    "    4: \"晩期\"\n",
    "}\n",
    "\n",
    "origin_order = [\"神津島\", \"信州\", \"箱根\", \"高原山\", \"その他\"]\n",
    "\n",
    "sigma = 14\n",
    "sigma_for_sites = 0.1\n",
    "\n",
    "# =======================================================================================\n",
    "\n",
    "# メッシュグリッドを作成\n",
    "lon_mesh, lat_mesh = np.meshgrid(\n",
    "    df_elevation['x'].unique().sort(),  # 経度の一意な値\n",
    "    df_elevation['y'].unique().sort()   # 緯度の一意な値\n",
    ")\n",
    "\n",
    "print(lon_mesh.shape, lat_mesh.shape)\n",
    "\n",
    "# データの前処理\n",
    "site_coords = create_site_coords(df_obsidian)\n",
    "\n",
    "# グリッド座標の準備\n",
    "grid_coords = np.column_stack([\n",
    "    lat_mesh.ravel() * np.pi / 180,\n",
    "    lon_mesh.ravel() * np.pi / 180\n",
    "])\n",
    "\n",
    "print(\"creating weights matrix...\")\n",
    "# 陸地のみの重み行列の計算\n",
    "weights = calculate_weights_matrix(\n",
    "    grid_coords, site_coords, sigma\n",
    ")\n",
    "print(\"updating weights matrix...\")\n",
    "\n",
    "# 重みの更新\n",
    "grid_is_land = create_land_mask(grid_coords, df_elevation, lon_mesh, lat_mesh)\n",
    "\n",
    "# 海上の点からの重みをすべて0に\n",
    "weights *= grid_is_land[:, np.newaxis]\n",
    "\n",
    "# 遺跡についての計算 ============================================================================\n",
    "        \n",
    "# 遺跡の一意な地点を取得\n",
    "unique_sites = df_obsidian.unique(subset=['遺跡ID']).sort('遺跡ID')\n",
    "\n",
    "# 計算対象の遺跡の座標をラジアンに変換\n",
    "target_coords_sites = np.column_stack([\n",
    "    unique_sites['緯度'].to_numpy() * np.pi / 180,\n",
    "    unique_sites['経度'].to_numpy() * np.pi / 180\n",
    "])\n",
    "\n",
    "# 距離行列の計算\n",
    "# 陸地のみの重み行列の計算\n",
    "weights_sites = calculate_weights_matrix(\n",
    "        target_coords_sites, site_coords, sigma_for_sites\n",
    ")\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "ratio_df = pl.DataFrame({\n",
    "    'x': lon_mesh.ravel(),\n",
    "    'y': lat_mesh.ravel()\n",
    "})\n",
    "\n",
    "ratio_sites_df = pl.DataFrame({\n",
    "    '遺跡ID': df_sites['遺跡ID']\n",
    "})\n",
    "\n",
    "\n",
    "for target_period in time_period_name.keys():\n",
    "    for target_origin in origin_order[:-1]:\n",
    "\n",
    "        print(f\"target_period: {target_period}, target_origin: {target_origin}\")\n",
    "\n",
    "        # ここからtarget_period, target_originに依存する処理\n",
    "        counts, target_counts = preprocess_data(\n",
    "            df_obsidian, target_period, target_origin\n",
    "        )\n",
    "\n",
    "        # 重み付き比率の計算\n",
    "        ratio_mesh = calculate_ratios(weights, counts, target_counts).reshape(lon_mesh.shape)\n",
    "        \n",
    "        ratio_df = ratio_df.join(\n",
    "            pl.DataFrame({\n",
    "                'x': lon_mesh.ravel(),\n",
    "                'y': lat_mesh.ravel(),\n",
    "                f\"ratio_{target_period}_{target_origin}\": ratio_mesh.ravel()\n",
    "            }),\n",
    "            on=[\"x\", \"y\"]\n",
    "        )\n",
    "        \n",
    "        # 比率の計算\n",
    "        ratios = calculate_ratios(weights_sites, counts, target_counts)\n",
    "\n",
    "        ratio_sites_df = ratio_sites_df.join(\n",
    "            pl.DataFrame({\n",
    "                '遺跡ID': unique_sites['遺跡ID'],\n",
    "                f\"比率_{target_period}_{target_origin}\": ratios\n",
    "            }),\n",
    "            on=\"遺跡ID\"\n",
    "        )\n",
    "\n",
    "df_elevation = df_elevation.join(\n",
    "    ratio_df,\n",
    "    on=[\"x\", \"y\"]\n",
    ")\n",
    "df_sites = df_sites.join(\n",
    "    ratio_sites_df,\n",
    "    on=\"遺跡ID\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "df_elevation.write_csv(os.path.join(data_dir, \"12_gdf_elevation_with_ratio.csv\"))\n",
    "df_sites.write_csv(os.path.join(data_dir, \"12_gdf_sites_with_ratio.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
